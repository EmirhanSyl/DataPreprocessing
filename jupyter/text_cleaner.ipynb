{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Cleaner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Union\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "from contractions import contractions_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_repetitive_words(dataframe: pd.DataFrame, column: Union[str, int]) -> pd.DataFrame:\n",
    "    if column not in dataframe.columns:\n",
    "        raise ValueError(f\"Column '{column}' not found in DataFrame.\")\n",
    "    assert pd.api.types.is_string_dtype(dataframe[column]), f\"Column '{column} is not string type'\"\n",
    "\n",
    "    def remove_duplicates(text):\n",
    "        if pd.isna(text):\n",
    "            return text\n",
    "        words = text.split()\n",
    "        seen = set()\n",
    "        unique_words = []\n",
    "        for word in words:\n",
    "            if word not in seen:\n",
    "                unique_words.append(word)\n",
    "                seen.add(word)\n",
    "        return ' '.join(unique_words)\n",
    "\n",
    "    df_copy = dataframe.copy()\n",
    "    df_copy[column] = df_copy[column].apply(remove_duplicates)\n",
    "    return df_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(dataframe: pd.DataFrame, column: Union[str, int]):\n",
    "    if column not in dataframe.columns:\n",
    "        raise ValueError(f\"Column '{column}' not found in DataFrame.\")\n",
    "    assert pd.api.types.is_string_dtype(dataframe[column]), f\"Column '{column} is not string type'\"\n",
    "    \n",
    "    df_copy = dataframe.copy()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    df_copy[column] = df_copy[column].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in stop_words]))\n",
    "    return df_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(dataframe: pd.DataFrame, column: Union[str, int]):\n",
    "    if column not in dataframe.columns:\n",
    "        raise ValueError(f\"Column '{column}' not found in DataFrame.\")\n",
    "    assert pd.api.types.is_string_dtype(dataframe[column]), f\"Column '{column} is not string type'\"\n",
    "    \n",
    "    df_copy = dataframe.copy()\n",
    "    df_copy[column] = df_copy[column].str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "    return df_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_words(dataframe: pd.DataFrame, column: Union[str, int], remove=['fword']):\n",
    "    if column not in dataframe.columns:\n",
    "        raise ValueError(f\"Column '{column}' not found in DataFrame.\")\n",
    "    assert pd.api.types.is_string_dtype(dataframe[column]), f\"Column '{column} is not string type'\"\n",
    "    \n",
    "    df_copy = dataframe.copy()\n",
    "    remove_set = set(remove)\n",
    "    df_copy[column] = df_copy[column].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in remove_set]))\n",
    "    return df_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(dataframe: pd.DataFrame, column: Union[str, int]):\n",
    "    if column not in dataframe.columns:\n",
    "        raise ValueError(f\"Column '{column}' not found in DataFrame.\")\n",
    "    assert pd.api.types.is_string_dtype(dataframe[column]), f\"Column '{column} is not string type'\"\n",
    "    \n",
    "    contraction_re = re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
    "    def expand_text(text):\n",
    "        def replace(match):\n",
    "            return contractions_dict[match.group(0)]\n",
    "        return contraction_re.sub(replace, text)\n",
    "    \n",
    "    df_copy = dataframe.copy()\n",
    "    df_copy[column] = df_copy[column].apply(lambda x: expand_text(x))\n",
    "    return df_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(dataframe: pd.DataFrame, column: Union[str, int]):\n",
    "    if column not in dataframe.columns:\n",
    "        raise ValueError(f\"Column '{column}' not found in DataFrame.\")\n",
    "    assert pd.api.types.is_string_dtype(dataframe[column]), f\"Column '{column} is not string type'\"\n",
    "    \n",
    "    df_copy = dataframe.copy()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    df_copy[column] = df_copy[column].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))\n",
    "    return df_copy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Director</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Key entire popular.</td>\n",
       "      <td>Anthony Becker</td>\n",
       "      <td>Horror</td>\n",
       "      <td>1981-05-12</td>\n",
       "      <td>102</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>husband reveal.</td>\n",
       "      <td>William Johnson</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>2016-06-13</td>\n",
       "      <td>92</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Crime cover.</td>\n",
       "      <td>Amy Le</td>\n",
       "      <td>Drama</td>\n",
       "      <td>1988-03-22</td>\n",
       "      <td>144</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Challenge.</td>\n",
       "      <td>Andrea Martinez</td>\n",
       "      <td>Romance</td>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>161</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Close study.</td>\n",
       "      <td>Michael Rodgers</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>2012-10-18</td>\n",
       "      <td>177</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>Daughter.</td>\n",
       "      <td>Richard Nelson</td>\n",
       "      <td>Romance</td>\n",
       "      <td>2007-03-12</td>\n",
       "      <td>177</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>Simply.</td>\n",
       "      <td>Jeffrey Hatfield</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>2011-08-16</td>\n",
       "      <td>126</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>Also authority nor.</td>\n",
       "      <td>Ryan Brown</td>\n",
       "      <td>Action</td>\n",
       "      <td>1998-05-07</td>\n",
       "      <td>73</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>Total report upon.</td>\n",
       "      <td>Melissa Stephenson</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>2008-06-06</td>\n",
       "      <td>145</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>Shoulder above note.</td>\n",
       "      <td>Cathy Edwards</td>\n",
       "      <td>Horror</td>\n",
       "      <td>2015-10-19</td>\n",
       "      <td>85</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Title            Director        Genre Release Date  \\\n",
       "0       Key entire popular.      Anthony Becker       Horror   1981-05-12   \n",
       "1           husband reveal.     William Johnson  Documentary   2016-06-13   \n",
       "2              Crime cover.              Amy Le        Drama   1988-03-22   \n",
       "3                Challenge.     Andrea Martinez      Romance   2013-04-01   \n",
       "4              Close study.     Michael Rodgers      Fantasy   2012-10-18   \n",
       "...                     ...                 ...          ...          ...   \n",
       "29995             Daughter.      Richard Nelson      Romance   2007-03-12   \n",
       "29996               Simply.    Jeffrey Hatfield      Fantasy   2011-08-16   \n",
       "29997   Also authority nor.          Ryan Brown       Action   1998-05-07   \n",
       "29998    Total report upon.  Melissa Stephenson       Comedy   2008-06-06   \n",
       "29999  Shoulder above note.       Cathy Edwards       Horror   2015-10-19   \n",
       "\n",
       "       Duration  Rating  \n",
       "0           102     6.8  \n",
       "1            92     7.6  \n",
       "2           144     5.5  \n",
       "3           161     2.0  \n",
       "4           177     3.7  \n",
       "...         ...     ...  \n",
       "29995       177     8.0  \n",
       "29996       126     5.7  \n",
       "29997        73     4.9  \n",
       "29998       145     6.9  \n",
       "29999        85     6.3  \n",
       "\n",
       "[30000 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset/movies.csv\")\n",
    "df['Release Date'] = pd.to_datetime(df['Release Date'], errors='coerce')\n",
    "filter_words(df, 'Title', ['gun'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
