{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Type Converter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import category_encoders as ce\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoding(dataframe: pd.DataFrame, column: Union[str, int]):\n",
    "    \"\"\"Convert categorical variables into numerical values\"\"\"\n",
    "    \n",
    "    if column not in dataframe.columns:\n",
    "        raise ValueError(f\"Column '{column}' not found in DataFrame.\")\n",
    "    \n",
    "    df_copy = dataframe.copy()\n",
    "    encoder = LabelEncoder()\n",
    "    df_copy[column] = encoder.fit_transform(df_copy[column])\n",
    "    return df_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(dataframe: pd.DataFrame, column: Union[str, int]):\n",
    "    if column not in dataframe.columns:\n",
    "        raise ValueError(f\"Column '{column}' not found in DataFrame.\")\n",
    "    \n",
    "    df_copy = dataframe.copy()\n",
    "    one_hot_encoded = pd.get_dummies(df_copy[column], prefix=column)\n",
    "    df_copy = df_copy.drop(column, axis=1)\n",
    "    df_copy = df_copy.join(one_hot_encoded)\n",
    "    return df_copy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Convertion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, MaxAbsScaler, PowerTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_data(dataframe: pd.DataFrame, column: Union[str, int]):\n",
    "    if column not in dataframe.columns:\n",
    "        raise ValueError(f\"Column '{column}' not found in DataFrame.\")\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(dataframe[column])\n",
    "    return pd.DataFrame(scaled_data, columns=dataframe.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(dataframe: pd.DataFrame, column: Union[str, int]):\n",
    "    if column not in dataframe.columns:\n",
    "        raise ValueError(f\"Column '{column}' not found in DataFrame.\")\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(dataframe[column])\n",
    "    return pd.DataFrame(scaled_data, columns=dataframe.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_vectors(dataframe: pd.DataFrame, column: Union[str, int]):\n",
    "    if column not in dataframe.columns:\n",
    "        raise ValueError(f\"Column '{column}' not found in DataFrame.\")\n",
    "    \n",
    "    norm = np.linalg.norm(dataframe[column], axis=1)\n",
    "    normalized_data = dataframe[column].div(norm, axis=0)\n",
    "    return pd.DataFrame(normalized_data, columns=dataframe.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Convertion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tfidf(dataframe: pd.DataFrame, column: Union[str, int]) -> pd.DataFrame:\n",
    "    \"\"\"Compute TF-IDF vectors for a list of text documents.\"\"\"\n",
    "    if column not in dataframe.columns:\n",
    "        raise ValueError(f\"Column '{column}' not found in DataFrame.\")\n",
    "    assert pd.api.types.is_string_dtype(dataframe[column]), f\"Column '{column} is not string type'\"\n",
    "    \n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(dataframe[column])\n",
    "    tfidf_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out(), index=dataframe.index)\n",
    "\n",
    "    return tfidf_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Director</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Key entire popular.</td>\n",
       "      <td>Anthony Becker</td>\n",
       "      <td>6</td>\n",
       "      <td>1981-05-12</td>\n",
       "      <td>102</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gun husband reveal.</td>\n",
       "      <td>William Johnson</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-06-13</td>\n",
       "      <td>92</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Crime cover.</td>\n",
       "      <td>Amy Le</td>\n",
       "      <td>4</td>\n",
       "      <td>1988-03-22</td>\n",
       "      <td>144</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Challenge.</td>\n",
       "      <td>Andrea Martinez</td>\n",
       "      <td>7</td>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>161</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Close study.</td>\n",
       "      <td>Michael Rodgers</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-10-18</td>\n",
       "      <td>177</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>Daughter.</td>\n",
       "      <td>Richard Nelson</td>\n",
       "      <td>7</td>\n",
       "      <td>2007-03-12</td>\n",
       "      <td>177</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>Simply.</td>\n",
       "      <td>Jeffrey Hatfield</td>\n",
       "      <td>5</td>\n",
       "      <td>2011-08-16</td>\n",
       "      <td>126</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>Also authority nor.</td>\n",
       "      <td>Ryan Brown</td>\n",
       "      <td>0</td>\n",
       "      <td>1998-05-07</td>\n",
       "      <td>73</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>Total report upon.</td>\n",
       "      <td>Melissa Stephenson</td>\n",
       "      <td>2</td>\n",
       "      <td>2008-06-06</td>\n",
       "      <td>145</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>Shoulder above note.</td>\n",
       "      <td>Cathy Edwards</td>\n",
       "      <td>6</td>\n",
       "      <td>2015-10-19</td>\n",
       "      <td>85</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Title            Director  Genre Release Date  Duration  \\\n",
       "0       Key entire popular.      Anthony Becker      6   1981-05-12       102   \n",
       "1       Gun husband reveal.     William Johnson      3   2016-06-13        92   \n",
       "2              Crime cover.              Amy Le      4   1988-03-22       144   \n",
       "3                Challenge.     Andrea Martinez      7   2013-04-01       161   \n",
       "4              Close study.     Michael Rodgers      5   2012-10-18       177   \n",
       "...                     ...                 ...    ...          ...       ...   \n",
       "29995             Daughter.      Richard Nelson      7   2007-03-12       177   \n",
       "29996               Simply.    Jeffrey Hatfield      5   2011-08-16       126   \n",
       "29997   Also authority nor.          Ryan Brown      0   1998-05-07        73   \n",
       "29998    Total report upon.  Melissa Stephenson      2   2008-06-06       145   \n",
       "29999  Shoulder above note.       Cathy Edwards      6   2015-10-19        85   \n",
       "\n",
       "       Rating  \n",
       "0         6.8  \n",
       "1         7.6  \n",
       "2         5.5  \n",
       "3         2.0  \n",
       "4         3.7  \n",
       "...       ...  \n",
       "29995     8.0  \n",
       "29996     5.7  \n",
       "29997     4.9  \n",
       "29998     6.9  \n",
       "29999     6.3  \n",
       "\n",
       "[30000 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset/movies.csv\")\n",
    "df['Release Date'] = pd.to_datetime(df['Release Date'], errors='coerce')\n",
    "label_encoding(df, 'Genre')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
